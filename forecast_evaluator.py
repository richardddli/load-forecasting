# forecast_evaluator.py
# Performs cross-validation on forecast model.

import forecaster
from sklearn.neural_network import MLPRegressor
from sklearn.model_selection import cross_val_score, TimeSeriesSplit
from sklearn import metrics

def cross_validate(load_data, holidays=None, short_term=True):
    df = forecaster.initialize(load_data)
    
    # generate predictor variables using all data
    times, predictors = forecaster.gen_predictors(df, holidays, short_term)
    predictors, loads = forecaster.clean_data(predictors, df)
    
    # split training and testing data; 25% test split
    train_X = predictors[:28000]
    test_X = predictors[28000:]
    train_Y = loads[:28000]
    test_Y = loads[28000:]
    train_X, test_X, scaler = forecaster.preprocess_data(train_X, test_X)
    
    mlp = MLPRegressor(hidden_layer_sizes=(30,30))
    mlp.fit(train_X, train_Y)
    print(mlp.score(test_X, test_Y))
    print(mlp.score(train_X, train_Y))

    # pass in indices generated by time series split to assess validation score
    tscv = TimeSeriesSplit(n_splits=5)       
    return cross_val_score(mlp, predictors, loads, cv=tscv, 
                           scoring='metrics.mean_absolute_error')

    